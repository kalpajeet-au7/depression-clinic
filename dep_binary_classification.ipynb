{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgjw9OaLM7PC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "Rj_F0kh7M_Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "iC2RJ13_NJ4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "RtFwQPdGNMUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional, SpatialDropout1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "fv_rqxyhMK3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/dep-bin/\""
      ],
      "metadata": {
        "id": "p8zzrIpthOh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path+'data/final.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "-DBfWuPjhl8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['target'].value_counts()"
      ],
      "metadata": {
        "id": "N6ReAaSOCHoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path+'clean-data/data-preprocess.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uC8myAoFEu4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text', 'label']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gcpa4pAvFFsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "sk4GB_PQFMn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['text'].astype(str), df['label'], test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "egM_zlNFFlvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using only Dense layer"
      ],
      "metadata": {
        "id": "cP5pnjm8I8pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining pre-processing parameters\n",
        "max_len = 250\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>' # out of vocabulary token\n",
        "vocab_size = 5000"
      ],
      "metadata": {
        "id": "2JBdZRRhFaEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, \n",
        "                      char_level = False,\n",
        "                      oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(x_train)"
      ],
      "metadata": {
        "id": "bhFLtb2sFqJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "training_padded = pad_sequences(training_sequences,\n",
        "                                maxlen = max_len,\n",
        "                                padding = padding_type,\n",
        "                                truncating = trunc_type)"
      ],
      "metadata": {
        "id": "b_mPOXsgGRzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "testing_padded = pad_sequences(testing_sequences,\n",
        "                               maxlen = max_len,\n",
        "                               padding = padding_type,\n",
        "                               truncating = trunc_type)\n"
      ],
      "metadata": {
        "id": "fMipF5qcGXOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training tensor: ', training_padded.shape)\n",
        "print('Shape of testing tensor: ', testing_padded.shape)"
      ],
      "metadata": {
        "id": "c_GmTMAeGa_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter\n",
        "vocab_size = 5000\n",
        "embedding_dim = 16\n",
        "drop_value = 0.2\n",
        "n_dense = 24\n",
        "# Define Dense Model Architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,\n",
        "                    embedding_dim,\n",
        "                    input_length = max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "zR4bV4uUIHQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "4IVxosL6IXzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded,\n",
        "                    y_train,\n",
        "                    epochs=num_epochs, \n",
        "                    validation_data=(testing_padded, y_test),\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "id": "LJu409DSIdcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dense_results = model.evaluate(training_padded, np.asarray(y_train), verbose=2, batch_size=256)\n",
        "valid_dense_results = model.evaluate(testing_padded, np.asarray(y_test), verbose=2, batch_size=256)\n",
        "print(f'Train accuracy: {train_dense_results[1]*100:0.2f}')\n",
        "print(f'Valid accuracy: {valid_dense_results[1]*100:0.2f}')"
      ],
      "metadata": {
        "id": "A4H4uND0I0Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM layer"
      ],
      "metadata": {
        "id": "YhwHtu5hJEdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter\n",
        "n_lstm = 128\n",
        "drop_lstm = 0.2\n",
        "# Define LSTM Model \n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model1.add(SpatialDropout1D(drop_lstm))\n",
        "model1.add(LSTM(200, return_sequences=False))\n",
        "model1.add(Dropout(drop_lstm))\n",
        "model1.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "FUzUBcEaJF6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss = 'binary_crossentropy',\n",
        "               optimizer = 'adam',\n",
        "               metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "eVSmLUjZJF4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
        "history = model1.fit(training_padded,\n",
        "                     y_train,\n",
        "                     epochs=num_epochs, \n",
        "                     validation_data=(testing_padded, y_test),\n",
        "                     verbose=2)"
      ],
      "metadata": {
        "id": "IS9iY-yLJF1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cKXalaPJFv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6nJsjmyyJFoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# without embedding layer"
      ],
      "metadata": {
        "id": "wQeGzK4XGU_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = np.load(path+'emb/mental-bert-emb.npy')\n",
        "label = np.load(path+'emb/mental-bert-label.npy')"
      ],
      "metadata": {
        "id": "RnaVIqXpw_uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(emb, label, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "amjyD_Zn-IyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "embedding_dim = 768"
      ],
      "metadata": {
        "id": "9iT86afMM1co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(embedding_dim))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PTVRxpGKNNkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "IjQni9ZLM6v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "# history = model.fit(train_emb, train_label, epochs=num_epochs, validation_data=(dev_emb, dev_label), verbose=1)\n"
      ],
      "metadata": {
        "id": "MivTVWaCM_yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 2)\n",
        "y_test = to_categorical(y_test, 2)"
      ],
      "metadata": {
        "id": "_yBQ0mGmVr3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "W0cHEW9PV8MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape([-1,1,768])#change value according to shape\n",
        "X_test = X_test.reshape([-1,1,768])"
      ],
      "metadata": {
        "id": "sykxlWJ6YCSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "1WwF_SFvYzWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "# model.add(Embedding(vocab_size, embedding_dim))\n",
        "# model.add(SpatialDropout1D(0.7))\n",
        "model2.add(LSTM(768, dropout=0.7, recurrent_dropout=0.7))\n",
        "#model.add(SpatialDropout1D(0.7))\n",
        "#model.add(LSTM(200, dropout=0.7, recurrent_dropout=0.7))\n",
        "model2.add(Dense(2, activation='sigmoid'))\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "l4WhtQmQNMAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.build()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "NaMgHvGlaFJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "XEeFyB5zVH_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "Dwq2fh-1nHAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BiLSTM"
      ],
      "metadata": {
        "id": "3VnY7FmVbZeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "# model.add(Embedding(vocab_size, embedding_dim))\n",
        "# model.add(SpatialDropout1D(0.7))\n",
        "model1.add(Bidirectional(LSTM(768, dropout=0.7, recurrent_dropout=0.7)))\n",
        "#model.add(SpatialDropout1D(0.7))\n",
        "#model.add(LSTM(200, dropout=0.7, recurrent_dropout=0.7))\n",
        "model1.add(Dense(2, activation='sigmoid'))\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "Hmm7tWOPViAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "JEY4-aqXbfbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "znPcu_4f7kRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "PT4L62qQn3VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argmax(pred, axis=-1)\n",
        "pred = np.zeros( pred.shape )\n",
        "pred[ np.arange(pred.shape[0]), idx] = 1"
      ],
      "metadata": {
        "id": "d23kJsVVodoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "b68qpF1HojEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy for stacked embeddings (without balancing)\")\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(pred, y_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "id": "JtyhffjAbg5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EV9kgzsH7p32"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}